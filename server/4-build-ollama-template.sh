export INFERENCE_MODEL="llama3.2:3b-instruct-fp16"
llama stack build --template ollama --image-type conda
